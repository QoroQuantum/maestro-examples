{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive Bond Dimension: CPU↔GPU Handoff\n",
    "\n",
    "This notebook demonstrates how Maestro makes it trivial to switch between CPU and GPU backends during MPS time evolution.\n",
    "\n",
    "**The key insight:**\n",
    "- At **low bond dimension** ($\\chi$), CPU is faster — no GPU transfer overhead\n",
    "- At **high $\\chi$**, GPU wins — tensor contractions benefit from parallelism\n",
    "- **Entanglement grows** during time evolution → $\\chi$ must increase\n",
    "- Maestro lets you switch with a **single argument change**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import maestro\n",
    "from maestro.circuits import QuantumCircuit\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: The Physical System\n",
    "\n",
    "We use the transverse-field Ising model (TFIM) on a 2D lattice:\n",
    "\n",
    "$$H = -J \\sum_{\\langle i,j \\rangle} Z_i Z_j - h \\sum_i X_i$$\n",
    "\n",
    "Time evolution via Trotterization generates increasing entanglement, which requires higher $\\chi$ for accurate MPS simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System parameters\n",
    "LX, LY = 6, 6\n",
    "N_QUBITS = LX * LY\n",
    "J, H_FIELD = 1.0, 1.0\n",
    "DT = 0.2\n",
    "N_STEPS = 10\n",
    "\n",
    "# Bond dimension settings\n",
    "CHI_LOW = 16    # Fast, approximate\n",
    "CHI_HIGH = 64   # Accurate, expensive\n",
    "\n",
    "# Set to True if you have an NVIDIA GPU with cuQuantum\n",
    "USE_GPU = False\n",
    "\n",
    "print(f\"Lattice: {LX}×{LY} = {N_QUBITS} qubits\")\n",
    "print(f\"Time: T={N_STEPS*DT:.1f}, {N_STEPS} steps\")\n",
    "print(f\"Bond dimensions: χ_low={CHI_LOW}, χ_high={CHI_HIGH}\")\n",
    "print(f\"GPU: {'Available' if USE_GPU else 'CPU only'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nn_bonds(lx, ly):\n",
    "    \"\"\"Nearest-neighbor bonds on a 2D square lattice.\"\"\"\n",
    "    bonds = []\n",
    "    for x in range(lx):\n",
    "        for y in range(ly):\n",
    "            q = x * ly + y\n",
    "            if x + 1 < lx:\n",
    "                bonds.append((q, (x + 1) * ly + y))\n",
    "            if y + 1 < ly:\n",
    "                bonds.append((q, q + 1))\n",
    "    return bonds\n",
    "\n",
    "def build_pauli_observable(n_qubits, pauli_map):\n",
    "    \"\"\"Build a Pauli observable string.\"\"\"\n",
    "    labels = ['I'] * n_qubits\n",
    "    for qubit, pauli in pauli_map.items():\n",
    "        labels[qubit] = pauli\n",
    "    return ''.join(labels)\n",
    "\n",
    "def build_tfim_circuit(n, bonds, j, h, dt, n_steps):\n",
    "    \"\"\"Build a Trotterized TFIM circuit.\"\"\"\n",
    "    qc = QuantumCircuit()\n",
    "    for q in range(n):\n",
    "        qc.h(q)\n",
    "    for _ in range(n_steps):\n",
    "        for q1, q2 in bonds:\n",
    "            qc.cx(q1, q2)\n",
    "            qc.rz(q2, 2.0 * j * dt)\n",
    "            qc.cx(q1, q2)\n",
    "        for q in range(n):\n",
    "            qc.h(q)\n",
    "            qc.rz(q, 2.0 * h * dt)\n",
    "            qc.h(q)\n",
    "    return qc\n",
    "\n",
    "bonds = get_nn_bonds(LX, LY)\n",
    "print(f\"Bonds: {len(bonds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_energy(qc, n, bonds, j, h, chi, use_gpu=False):\n",
    "    \"\"\"Compute TFIM energy via MPS estimate().\"\"\"\n",
    "    obs = []\n",
    "    for q1, q2 in bonds:\n",
    "        obs.append(build_pauli_observable(n, {q1: 'Z', q2: 'Z'}))\n",
    "    for q in range(n):\n",
    "        obs.append(build_pauli_observable(n, {q: 'X'}))\n",
    "    \n",
    "    sim_type = (maestro.SimulatorType.CuQuantum if use_gpu\n",
    "                else maestro.SimulatorType.QCSim)\n",
    "    \n",
    "    result = qc.estimate(\n",
    "        simulator_type=sim_type,\n",
    "        simulation_type=maestro.SimulationType.MatrixProductState,\n",
    "        observables=obs,\n",
    "        max_bond_dimension=chi,\n",
    "    )\n",
    "    \n",
    "    exp_vals = result['expectation_values']\n",
    "    n_bonds = len(bonds)\n",
    "    e_zz = sum(-j * exp_vals[i] for i in range(n_bonds))\n",
    "    e_x = sum(-h * exp_vals[n_bonds + i] for i in range(n))\n",
    "    return e_zz + e_x\n",
    "\n",
    "print(\"✓ Energy computation function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Compare Low χ vs High χ\n",
    "\n",
    "First, let's see the difference in accuracy and speed between low and high bond dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_time_evolution(chi, use_gpu=False, label=\"\"):\n",
    "    \"\"\"Run full time evolution at a fixed χ.\"\"\"\n",
    "    print(f\"\\n── {label}: χ={chi}, {'GPU' if use_gpu else 'CPU'} ──\")\n",
    "    \n",
    "    energies, times, step_times = [], [], []\n",
    "    \n",
    "    for step in range(N_STEPS + 1):\n",
    "        t0 = time.time()\n",
    "        if step == 0:\n",
    "            energy = -N_QUBITS\n",
    "        else:\n",
    "            qc = build_tfim_circuit(N_QUBITS, bonds, J, H_FIELD, DT, step)\n",
    "            energy = compute_energy(qc, N_QUBITS, bonds, J, H_FIELD, chi, use_gpu)\n",
    "        wall = time.time() - t0\n",
    "        \n",
    "        energies.append(energy)\n",
    "        times.append(step * DT)\n",
    "        step_times.append(wall)\n",
    "        \n",
    "        if step % 2 == 0:\n",
    "            print(f\"  step {step:2d}  t={step*DT:.2f}  E={energy:10.4f}  ({wall:.3f}s)\")\n",
    "    \n",
    "    avg = np.mean(step_times[1:])\n",
    "    print(f\"  → avg: {avg:.3f}s/step, total: {sum(step_times):.1f}s\")\n",
    "    \n",
    "    return {'energies': energies, 'times': times, \n",
    "            'step_times': step_times, 'avg': avg,\n",
    "            'chi': chi, 'use_gpu': use_gpu, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 1: Low χ on CPU\n",
    "r_low = run_time_evolution(CHI_LOW, use_gpu=False, label=\"Low χ (CPU)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 2: High χ on CPU\n",
    "r_high = run_time_evolution(CHI_HIGH, use_gpu=False, label=\"High χ (CPU)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 3: High χ on GPU (if available)\n",
    "r_gpu = None\n",
    "if USE_GPU:\n",
    "    r_gpu = run_time_evolution(CHI_HIGH, use_gpu=True, label=\"High χ (GPU)\")\n",
    "else:\n",
    "    print(\"Skipping GPU run (set USE_GPU = True to enable)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Adaptive Handoff\n",
    "\n",
    "Start at low χ (fast, CPU). When the energy change signals growing entanglement, switch to high χ (GPU if available).\n",
    "\n",
    "Notice how **the code is identical** — we just change `max_bond_dimension` and `simulator_type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.5  # Handoff when |ΔE| exceeds this\n",
    "\n",
    "print(f\"\\n── ADAPTIVE: χ={CHI_LOW} → χ={CHI_HIGH} ──\")\n",
    "print(f\"Handoff when |ΔE| > {THRESHOLD}\\n\")\n",
    "\n",
    "a_energies, a_times, a_step_times, a_backends = [], [], [], []\n",
    "switched = False\n",
    "\n",
    "for step in range(N_STEPS + 1):\n",
    "    chi = CHI_LOW if not switched else CHI_HIGH\n",
    "    use_gpu = False if not switched else USE_GPU\n",
    "    backend = 'low' if not switched else 'high'\n",
    "    \n",
    "    t0 = time.time()\n",
    "    if step == 0:\n",
    "        energy = -N_QUBITS\n",
    "    else:\n",
    "        qc = build_tfim_circuit(N_QUBITS, bonds, J, H_FIELD, DT, step)\n",
    "        energy = compute_energy(qc, N_QUBITS, bonds, J, H_FIELD, chi, use_gpu)\n",
    "    wall = time.time() - t0\n",
    "    \n",
    "    a_energies.append(energy)\n",
    "    a_times.append(step * DT)\n",
    "    a_step_times.append(wall)\n",
    "    a_backends.append(backend)\n",
    "    \n",
    "    label = f\"CPU χ={CHI_LOW}\" if not switched else f\"{'GPU' if USE_GPU else 'CPU'} χ={CHI_HIGH}\"\n",
    "    if step % 2 == 0:\n",
    "        print(f\"  step {step:2d}  t={step*DT:.2f}  E={energy:10.4f}  {label}  ({wall:.3f}s)\")\n",
    "    \n",
    "    if not switched and step >= 2:\n",
    "        if abs(a_energies[-1] - a_energies[-2]) > THRESHOLD:\n",
    "            switched = True\n",
    "            print(f\"\\n  ⚡ HANDOFF at step {step}: switching to {label}\\n\")\n",
    "\n",
    "print(f\"\\n✓ Adaptive run complete\")\n",
    "print(f\"  Low-χ steps: {sum(1 for b in a_backends if b == 'low')}\")\n",
    "print(f\"  High-χ steps: {sum(1 for b in a_backends if b == 'high')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Left: Energy evolution\n",
    "ax1 = axes[0]\n",
    "ax1.plot(r_low['times'], r_low['energies'], '--',\n",
    "         color='#2196F3', linewidth=1.5, alpha=0.6,\n",
    "         label=f'CPU χ={CHI_LOW}')\n",
    "ax1.plot(r_high['times'], r_high['energies'], '--',\n",
    "         color='#FF9800', linewidth=1.5, alpha=0.6,\n",
    "         label=f'CPU χ={CHI_HIGH}')\n",
    "if r_gpu:\n",
    "    ax1.plot(r_gpu['times'], r_gpu['energies'], '--',\n",
    "             color='#4CAF50', linewidth=1.5, alpha=0.6,\n",
    "             label=f'GPU χ={CHI_HIGH}')\n",
    "\n",
    "# Adaptive: color by backend\n",
    "for i in range(1, len(a_times)):\n",
    "    c = '#2196F3' if a_backends[i] == 'low' else '#E91E63'\n",
    "    ax1.plot(a_times[i-1:i+1], a_energies[i-1:i+1], '-',\n",
    "             color=c, linewidth=3)\n",
    "ax1.plot([], [], '-', color='#2196F3', linewidth=3,\n",
    "         label=f'Adaptive low (χ={CHI_LOW})')\n",
    "ax1.plot([], [], '-', color='#E91E63', linewidth=3,\n",
    "         label=f'Adaptive high (χ={CHI_HIGH})')\n",
    "\n",
    "ax1.set_xlabel('Simulation Time t', fontsize=12)\n",
    "ax1.set_ylabel('Energy E(t)', fontsize=12)\n",
    "ax1.set_title(f'Time Evolution — {LX}×{LY} TFIM', fontsize=14)\n",
    "ax1.legend(fontsize=9)\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Right: Per-step timing\n",
    "ax2 = axes[1]\n",
    "bar_labels = [f'CPU\\nχ={CHI_LOW}', f'CPU\\nχ={CHI_HIGH}']\n",
    "bar_vals = [r_low['avg'], r_high['avg']]\n",
    "bar_colors = ['#2196F3', '#FF9800']\n",
    "\n",
    "if r_gpu:\n",
    "    bar_labels.append(f'GPU\\nχ={CHI_HIGH}')\n",
    "    bar_vals.append(r_gpu['avg'])\n",
    "    bar_colors.append('#4CAF50')\n",
    "\n",
    "bar_labels.append(f'Adaptive\\n{CHI_LOW}→{CHI_HIGH}')\n",
    "bar_vals.append(np.mean(a_step_times[1:]))\n",
    "bar_colors.append('#9C27B0')\n",
    "\n",
    "bars = ax2.bar(range(len(bar_vals)), bar_vals,\n",
    "               color=bar_colors, edgecolor='black', alpha=0.8)\n",
    "ax2.set_xticks(range(len(bar_vals)))\n",
    "ax2.set_xticklabels(bar_labels, fontsize=10)\n",
    "ax2.set_ylabel('Avg Time per Step (s)', fontsize=12)\n",
    "ax2.set_title('Per-Step Cost', fontsize=14)\n",
    "ax2.grid(alpha=0.3, axis='y')\n",
    "\n",
    "for bar, val in zip(bars, bar_vals):\n",
    "    ax2.annotate(f'{val:.3f}s', (bar.get_x() + bar.get_width()/2, val),\n",
    "                 textcoords='offset points', xytext=(0, 5),\n",
    "                 ha='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Key Takeaway: Switching Backends is One Line\n",
    "\n",
    "The entire CPU→GPU switch is just changing the `simulator_type` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU backend\n",
    "# result = qc.estimate(\n",
    "#     simulator_type=maestro.SimulatorType.QCSim,       # ← CPU\n",
    "#     simulation_type=maestro.SimulationType.MatrixProductState,\n",
    "#     max_bond_dimension=64,\n",
    "# )\n",
    "\n",
    "# GPU backend — same code, one argument changed\n",
    "# result = qc.estimate(\n",
    "#     simulator_type=maestro.SimulatorType.CuQuantum,   # ← GPU\n",
    "#     simulation_type=maestro.SimulationType.MatrixProductState,\n",
    "#     max_bond_dimension=64,\n",
    "# )\n",
    "\n",
    "print(\"Same API. Same code. Just change simulator_type.\")\n",
    "print(\"No code rewrite. No separate GPU code paths.\")\n",
    "print(\"Maestro handles the backend switch transparently.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**What we demonstrated:**\n",
    "- Low $\\chi$ is fast but loses accuracy as entanglement grows\n",
    "- High $\\chi$ is accurate but ~20× slower per step\n",
    "- GPU acceleration makes high $\\chi$ practical (when available)\n",
    "- **Adaptive switching** gives you accuracy when it matters, speed when it doesn't\n",
    "- Switching between CPU/GPU backends is a **single argument change**\n",
    "\n",
    "**Key Maestro APIs:**\n",
    "- `SimulatorType.QCSim` — CPU backend\n",
    "- `SimulatorType.CuQuantum` — GPU backend\n",
    "- `max_bond_dimension=χ` — accuracy vs speed control\n",
    "- `qc.estimate(observables=...)` — compute expectation values\n",
    "\n",
    "**To try with GPU:** Set `USE_GPU = True` in Step 1 (requires NVIDIA GPU + cuQuantum)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
